Courtesy:  Jared Hoberock  of NVIDIA

The content below is an edited version of the original content by Jared Hoberock which is  licensed under the Apache License version 2.0 


__device__ Functions

The __device__ keyword lets us mark functions as callable from threads executing on the device. The syntax is like the __global__ keyword: we just prepend it to the function signature:

 
__device__ float my_device_function(float x)
 {
   return x + 1;
 }


Though __device__ functions are similar to __global__ functions in that they are executed by device threads, they actually behave more like normal C functions. Unlike __global__ functions, __device__ functions cannot be configured (no <<<B,T>>> needed) and aren't subject to any special restrictions on the types of their parameters or results. Host code isn't allowed to call __device__ functions directly -- if we want access to the functionality in a __device__ function, we need to write a __global__ function to call it for us! 




As you might expect, __device__ functions can call other functions decorated with __device__: 



__device__ float my_second_device_function(float y)
 {
   return my_device_function(y) / 2;
 }



As long as they don't call themselves: 


__device__ int my_illegal_recursive_device_function(int x)
 {
   if(x == 0) return 1;
   return x * my_illegal_recursive_device_function(x-1);
 }



The following code listing shows how we might use __device__ functions to package up various bits of code when developing a CUDA kernel. 



// This example introduces __device__ functions, which are special functions
// which may be called from code executing on the device.

#include <stdlib.h>
#include <stdio.h>


// __device__ functions may only be called from __global__ functions or other
// __device__ functions.  Unlike __global__ functions, __device__ functions are
// not configured, and have no restriction on return type.
__device__ int get_constant(void)
{
  // just return 7
  return 7;
}

__device__ int get_block_index(void)
{
  // return the index of the current thread's block
  return blockIdx.x;
}

__device__ int get_thread_index(void)
{
  // return the index of the current thread within its block
  return threadIdx.x;
}

__device__ int get_global_index(void)
{
  // return the index of the current thread across the entire grid launch
  return blockIdx.x * blockDim.x + threadIdx.x;
}


// kernel1 returns the result of calling the __device__ function return_constant():
__global__ void kernel1(int *array)
{
  int index = get_global_index();
  array[index] = get_constant();
}


// kernel2 returns the result of calling the __device__ function return_block_index():
__global__ void kernel2(int *array)
{
  int index = get_global_index();
  array[index] = get_block_index();
}


// kernel3 returns the result of calling the __device__ function return_thread_index():
__global__ void kernel3(int *array)
{
  int index = get_global_index();
  array[index] = get_thread_index();
}


// kernel4 returns the result of calling the __device__ function return_thread_index():
__global__ void kernel4(int *array)
{
  int index = get_global_index();
  array[index] = get_global_index();
}


int main(void)
{
  int num_elements = 256;

  int num_bytes = num_elements * sizeof(int);

  int *device_array = 0;
  int *host_array = 0;

  // malloc a host array
  host_array = (int*)malloc(num_bytes);

  // cudaMalloc a device array
  cudaMalloc((void**)&device_array, num_bytes);

  // if either memory allocation failed, report an error message
  if(host_array == 0 || device_array == 0)
  {
    printf("couldn't allocate memory\n");
    return 1;
  }

  // choose a launch configuration
  int block_size = 128;
  int grid_size = num_elements / block_size;

  // launch each kernel and print out the results

  kernel1<<<grid_size,block_size>>>(device_array);

  cudaMemcpy(host_array, device_array, num_bytes, cudaMemcpyDeviceToHost);

  printf("kernel1 results:\n");
  for(int i=0; i < num_elements; ++i)
  {
    printf("%d ", host_array[i]);
  }
  printf("\n\n");


  kernel2<<<grid_size,block_size>>>(device_array);

  cudaMemcpy(host_array, device_array, num_bytes, cudaMemcpyDeviceToHost);

  printf("kernel2 results:\n");
  for(int i=0; i < num_elements; ++i)
  {
    printf("%d ", host_array[i]);
  }
  printf("\n\n");


  kernel3<<<grid_size,block_size>>>(device_array);

  cudaMemcpy(host_array, device_array, num_bytes, cudaMemcpyDeviceToHost);

  printf("kernel3 results:\n");
  for(int i=0; i < num_elements; ++i)
  {
    printf("%d ", host_array[i]);
  }
  printf("\n\n");


  kernel4<<<grid_size,block_size>>>(device_array);

  cudaMemcpy(host_array, device_array, num_bytes, cudaMemcpyDeviceToHost);

  printf("kernel4 results:\n");
  for(int i=0; i < num_elements; ++i)
  {
    printf("%d ", host_array[i]);
  }
  printf("\n\n");


  // deallocate memory
  free(host_array);
  cudaFree(device_array);
}




This is the first time we've included more than one __global__ function in our example. This is fine -- they're just like C functions in this way. Note also that both kernel1 and kernel2 can call any of the __device__ functions they can "see". The usual C/C++ scoping rules apply. 

For kernel1, we've essentially taken our __global__ function from a previous section and refactored it into __device__ functions get_global_index and get_constant. get_constant isn't so useful, but get_global_index encapsulates the tedious calculation of each CUDA thread's global index in the grid. Rather than repeating ourself, both kernels can simply call the __device__ function. Note that get_global_index uses the built-in variables blockIdx, blockDim, and threadIdx, which are available to __device__ functions as they are to __global__ functions.
